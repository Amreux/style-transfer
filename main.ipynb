{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T20:36:07.386339Z",
     "start_time": "2023-12-11T20:36:07.350373Z"
    }
   },
   "outputs": [],
   "source": [
    "from Common_Functions.CommonFunctions import *\n",
    "from Patches_Functions.ExtractPatches import extract_patches\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from color_transfer import color_transfer\n",
    "# from irls import irls\n",
    "# from segmentation.FaceDetectionSegmentation import segement\n",
    "import cv2\n",
    "from skimage.transform import pyramid_gaussian\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T22:11:56.962982300Z",
     "start_time": "2023-12-11T22:11:40.405697Z"
    }
   },
   "outputs": [],
   "source": [
    "def irls(X,z,r,Iirls,patch_size,subsampling_gap):\n",
    "    Xp=extract_patches(X,patch_size,subsampling_gap)\n",
    "    num_of_patches=(np.shape(Xp)[0])*(np.shape(Xp)[1])\n",
    "    w=(np.ones((num_of_patches,1)))\n",
    "    # z should be initialized with patch matching\n",
    "    print(np.shape(Xp)[0], np.shape(Xp)[1])\n",
    "    print(np.shape(z), np.shape(Xp))\n",
    "    for i in range(0, Iirls):\n",
    "        for x in range(0, np.shape(Xp)[0]):\n",
    "            for y in range(0,np.shape(Xp)[1]):\n",
    "                e=Xp[x,y,0,:,:,:]-z[x*np.shape(Xp)[1]+y]\n",
    "                e2=np.sum(e**2)**0.5+0.00001\n",
    "                w[x*np.shape(Xp)[1]+y]=(e2**(r-2))\n",
    "                Xp[x,y,0,:,:,:]+=(z[x*np.shape(Xp)[1]+y]-Xp[x,y,0,:,:,:])*w[x*np.shape(Xp)[1]+y]\n",
    "\n",
    "\n",
    "def segement(image):\n",
    "\n",
    "\n",
    "    # initialize the mask\n",
    "    mask = np.zeros(image.shape[:2], np.uint8)\n",
    "\n",
    "    # not sure what these are for in the algorithm\n",
    "    backgroundModel = np.zeros((1, 65), np.float64) \n",
    "    foregroundModel = np.zeros((1, 65), np.float64) \n",
    "\n",
    "\n",
    "    img_height=image.shape[0]\n",
    "    img_width= image.shape[1]\n",
    "   \n",
    "\n",
    "   # initialize a rectangle for the grabcut algorithm\n",
    "    rectangle = (1,1,img_width,img_height)\n",
    "\n",
    "    # run the grabcut algorithm for 8 iterations\n",
    "    cv2.grabCut(image, mask, rectangle, backgroundModel, foregroundModel, 10, cv2.GC_INIT_WITH_RECT) \n",
    "   \n",
    "\n",
    "    # generate the forground mask\n",
    "    mask_forground = np.where((mask == 2)|(mask == 0), 0, 1).astype('uint8') \n",
    "\n",
    "    # get the final image\n",
    "    result_img = image * mask_forground[:, :, np.newaxis] \n",
    "\n",
    " \n",
    "    result_mask = np.where((result_img>0),1,0).astype(float)\n",
    "\n",
    "    # print(result_mask)\n",
    "\n",
    "    return result_mask\n",
    "\n",
    "\n",
    "def color_transfer(content,style):\n",
    "    content=cv2.cvtColor(content, cv2.COLOR_BGR2LAB)\n",
    "    style=cv2.cvtColor(style, cv2.COLOR_BGR2LAB)    \n",
    "    content[:,:,0]-=np.mean(content[:,:,0])\n",
    "    content[:,:,1]-=np.mean(content[:,:,1])\n",
    "    content[:,:,2]-=np.mean(content[:,:,2])\n",
    "    content[:,:,0]*=(np.std(style[:,:,0])/(np.std(content[:,:,0])+0.00001))\n",
    "    content[:,:,1]*=(np.std(style[:,:,1]/(np.std(content[:,:,1])+0.00001)))\n",
    "    content[:,:,2]*=(np.std(style[:,:,2]/(np.std(content[:,:,2])+0.00001)))\n",
    "    content[:,:,0]+=np.mean(style[:,:,0])\n",
    "    content[:,:,1]+=np.mean(style[:,:,1])\n",
    "    content[:,:,2]+=np.mean(style[:,:,2])\n",
    "    return cv2.cvtColor(content.astype(np.float32), cv2.COLOR_LAB2BGR)\n",
    "\n",
    "\n",
    "def style_transfer(content, style, r, L, Iirls, patch_sizes, subsampling_gaps, Ialg, seg_mask):\n",
    "    content = color_transfer(content,style)\n",
    "    # content = np.pad(content, ((patch_sizes[0], patch_sizes[0]), (patch_sizes[0], patch_sizes[0]), (0, 0)))\n",
    "    # seg_mask = np.pad(seg_mask, ((patch_sizes[0], patch_sizes[0]), (patch_sizes[0], patch_sizes[0]), (0, 0)))\n",
    "    content_pyramid_tuple = tuple(pyramid_gaussian(content, channel_axis=-1, max_layer=L, downscale=1.5))\n",
    "    style_pyramid_tuple = tuple(pyramid_gaussian(style, channel_axis=-1, max_layer=L, downscale=1.5))\n",
    "    w_pyramid_tuple = tuple(pyramid_gaussian(seg_mask, channel_axis=-1, max_layer=L, downscale=1.5))\n",
    "    \n",
    "    content_pyramid = []\n",
    "    style_pyramid = []\n",
    "    w_pyramid = []  \n",
    "    for i in range (0,L):\n",
    "        content_pyramid.append(content_pyramid_tuple[i])\n",
    "        style_pyramid.append(style_pyramid_tuple[i])\n",
    "        w_pyramid.append(w_pyramid_tuple[i])\n",
    "    X = content_pyramid[L-1]\n",
    "    # X= random_noise(content_pyramid[L-1], mode=\"gaussian\",mean=0,var=50)\n",
    "    for l in range (L-1,-1,-1):\n",
    "        X = np.pad(X, ((0, patch_sizes[0]), (0, patch_sizes[0]), (0, 0)), mode='constant', constant_values=(1,1))\n",
    "        if(l == L-1):\n",
    "            X= random_noise(X, mode=\"gaussian\",mean=0,var=50)\n",
    "        else:\n",
    "            X= random_noise(X, mode=\"gaussian\",mean=0,var=1)\n",
    "        content_pyramid[l] = np.pad(content_pyramid[l], ((0, patch_sizes[0]), (0, patch_sizes[0]), (0,0)), mode='constant', constant_values=(1,1))\n",
    "        w_pyramid[l] = np.pad(w_pyramid[l], ((0, patch_sizes[0]), (0, patch_sizes[0]), (0, 0)), mode='constant', constant_values=(1,1))\n",
    "        for s in range(0,len(patch_sizes)):\n",
    "            style_patches =  extract_patches(style_pyramid[l],(patch_sizes[s], patch_sizes[s], 3),subsampling_gaps[s])\n",
    "            flatten_style_patches = style_patches.reshape(-1, patch_sizes[s] * patch_sizes[s] * 3)\n",
    "            nn_model = NearestNeighbors(n_neighbors=1).fit(flatten_style_patches)    \n",
    "            z=[]\n",
    "            for k in range(0,Ialg):\n",
    "                Xp=extract_patches(X,(patch_sizes[s], patch_sizes[s], 3),subsampling_gaps[s])\n",
    "                flatten_Xp = Xp.reshape(-1, patch_sizes[s] * patch_sizes[s] * 3)\n",
    "                for Xpatch in flatten_Xp:\n",
    "                   Xpatch = [Xpatch]     \n",
    "                   flatten_neighbour_patch = flatten_style_patches[nn_model.kneighbors(Xpatch)[1][0][0]]\n",
    "                   z.append(flatten_neighbour_patch.reshape(patch_sizes[s], patch_sizes[s], 3))\n",
    "                irls(X,z,r,Iirls,(patch_sizes[s],patch_sizes[s],3),subsampling_gaps[s]) \n",
    "                X=color_transfer(X.astype(np.float32),style_pyramid[l].astype(np.float32))\n",
    "                X =((1.0-w_pyramid[l])* X).astype(np.float32) + (w_pyramid[l].astype(np.float32)*content_pyramid[l]).astype(np.float32)\n",
    "                show_images([X])\n",
    "        if (l>0) : \n",
    "            X = cv2.resize(X, (np.shape(content_pyramid[l-1])[1], np.shape(content_pyramid[l-1])[0]))       \n",
    "        #remove padding\n",
    "        X = X[0:-patch_sizes[0], 0:-patch_sizes[0], :]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "style=io.imread(\"imgs/starry.jpg\").astype(np.float32)/255\n",
    "X=io.imread(\"imgs/vat.jpg\").astype(np.float32)/255\n",
    "# X = color_transfer(X,style)\n",
    "\n",
    "con = io.imread(\"imgs/vat.jpg\")\n",
    "seg_mask = segement(con)\n",
    "\n",
    "# X= random_noise(X, mode=\"gaussian\",mean=0,var=0.01)\n",
    "# print(X.shape, style.shape)\n",
    "# shape = 40\n",
    "# Xp=extract_patches(X,(shape,shape,3),shape)\n",
    "# style_patches =  extract_patches(style,(shape,shape,3),shape)\n",
    "# z=[]\n",
    "# style_patches = style_patches.reshape(-1, shape * shape * 3)\n",
    "# nn_model = NearestNeighbors(n_neighbors=1).fit(style_patches)\n",
    "# \n",
    "# print(X.shape)\n",
    "# Xp = Xp.reshape(-1, shape * shape * 3)\n",
    "# \n",
    "# print(Xp[0], style_patches[0])\n",
    "# \n",
    "# print(4, (Xp.shape))\n",
    "# for Xpatch in Xp:\n",
    "# \n",
    "#     temp_arr = [Xpatch]\n",
    "#     index = nn_model.kneighbors(temp_arr)[1][0][0] \n",
    "#     print(index, nn_model.kneighbors(temp_arr)[0][0][0])\n",
    "#     paa = style_patches[index]\n",
    "#     z.append(style_patches[index])\n",
    "#     #now do un reshape to be 20*20*3\n",
    "#     new_patch = paa.reshape(shape,shape,3)\n",
    "#     show_images([new_patch, Xpatch.reshape(shape,shape,3)])\n",
    "\n",
    "    # X = np.array(z) # should be replaced by the new xpatches generated from irls\n",
    "\n",
    "# show_images([X])\n",
    "#content,style,r,L,Iirls,patch_sizes,subsampling_gaps, Ialg\n",
    "style_transfer(X,style,0.8,5,10,[33, 21, 13,9],[28, 18, 8,5],3, seg_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T19:14:12.314655200Z",
     "start_time": "2023-12-11T19:14:07.375124800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "style=io.imread(\"imgs/starry.jpg\").astype(np.float32)/255\n",
    "\n",
    "X=np.ones(np.shape(style)).astype(np.float32)\n",
    "X = color_transfer(X,style)\n",
    "con = io.imread(\"imgs/starry.jpg\")\n",
    "seg_mask = segement(con)\n",
    "# X=random_noise(content, mode=\"gaussian\",mean=0,var=0.002)\n",
    "# show_images([X])\n",
    "style_transfer(X,style,0.8,1,3,[40],[40],2,con)\n",
    "# show_images([style,X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
